Simple_Different Same The standard recombination history is tested in the Planck 2018 analysis by using a semi-blind eigen-analysis, which is a form of principal-component analysis. This method examines deviations of the free-electron fraction, xe(z), from the standard recombination history. The results indicate that there are no significant departures from the standard prediction, and the reconstructed recombination histories are consistent with the standard scenario. Additionally, including ACT data enhances the constraints on the free-electron fraction, particularly at high redshifts. 2503.14454v1.pdf	semi-blind eigen-analysis (often referred to as a principal-component analysis) 

Simple_Different Different In the 2018 Planck analysis, corrections implemented in the polarization spectra included:1. **Beam-leakage correction**: This correction addressed temperature-to-polarization leakage caused by beam mismatch. It utilized polarized beam matrices computed with the QuickPol code, and the correction template was based on fiducial theoretical spectra from the best-fit ΛCDM cosmology.2. **Effective polarization efficiencies**: The analysis estimated the effective polarization efficiencies of the SRoll maps by comparing the frequency polarization power spectra to fiducial spectra derived from the best-fit base-ΛCDM model based on temperature data. 1807.06209v4.pdf	Beam leakage correction; effective polarization efficiencies; Correlated noise in auto-frequency cross-spectra and sub-pixel effects

Simple_Different Same For the 143 × 217 spectrum in the Camspec temperature likelihood for the Planck 2018 analysis, the multipole cuts applied are `min = 500` and `max = 2500`. These minimum cuts are specifically imposed to reduce potential systematic biases arising from Galactic dust at these frequencies. 1807.06209v4.pdf	lmin=500, lmax=2500

Simple_Different Same The effective sky-fraction of the apodized Camspec polarization mask for the Planck 2018 analysis is f W sky = 47.7 %. 1807.06209v4.pdf	47.70%

Simple_Different Same The impact of beam window functions on the 2018 spectra in the baseline Plik likelihood is small, approximately 0.1% at ` = 2000. [4:0†source]	approximately 0.1% at l=2000

Simple_Different Same The 68% confidence level (CL) constraint on the acoustic scale from the Planck TT+lowE analysis in 2018 is given as 100θ∗ = 1.04097 ± 0.00046. 1807.06209v4.pdf	1.04097\pm0.00046

Simple_Different Same The 1-sigma constraint on As with TT, TE, EE + lowE from Planck 2018 is As = (2.101 +0.031 −0.034) × 10−9 at a 68% confidence level. 1807.06209v4.pdf	(2.101^{+0.031}_{-0.034})\times 10^{-9}

Simple_Different Same The apparent preference for A_L deviating from theoretical expectations in the Planck 2018 analysis can be attributed to several factors. Firstly, within the ΛCDM model, there is a notable preference for A_L > 1, which has been discussed in previous analyses (PCP13, PCP15, and Planck Collaboration Int. LI, 2017) and is now slightly more significant. In terms of temperature data, over half of the small upward shift in A_L compared to 2015 is explained by a lower optical depth (τ) from the 2018 low-` likelihood. A lower τ leads to a lower amplitude of scalar perturbations (A_s) to match the high-` CMB fluctuation amplitude, necessitating a larger A_L to maintain the lensing amplitude and smoothing consistent with previous findings.In polarization data, about 40% of the shift in A_L is also attributed to changes in τ, with additional contributions from changes in maps, modeling for beam leakage, and polarization efficiencies. The high-` temperature likelihood indicates a preference for more lensing smoothing than what is allowed by the ΛCDM model, which is visually evident in the smoothed data residuals. This oscillatory residual in the range 1100 < ` < 2000 aligns with the lensing smoothing shape.Moreover, when considering the CMB spectra alone, after removing low multipoles (` < 30), A_L from temperature and temperature-polarization (TT) data is consistent with unity within 1σ. However, the large ΛCDM lensing amplitudes still yield a value of Ω_mσ8 that is in 2σ tension with lensing reconstruction. If the preference for A_L > 1 is not merely a statistical fluctuation, it may suggest new physics that alters theoretical predictions, potentially mimicking the smoothing effect observed in the CMB peaks. One proposed explanation for this is the presence of large-scale compensated isocurvature modes. 1807.06209v4.pdf	In temperature, over half of the small upward shift in A_L is explained by the lower optical depth from the 2018 low-l likelihood, In polarization, the shift in A_L is explained by changes in \tau, with changes in the maps, modelling for beam leakage, and polarization efficiencies.

Simple_Same Same The PTE (probability to exceed) for the SPTpol TE spectrum compared to the Planck 2018 best-fit parameters is 0.64, indicating no significant inconsistency between the two sets of parameters. 1807.06209v4.pdf	0.64

Simple_Different Same In the Planck analysis, systematic errors in X-ray cluster masses are corrected by applying a "hydrostatic mass bias" factor, denoted as (1 − b). This factor accounts for the expected bias in X-ray derived masses, which are assumed to be low due to the assumption of hydrostatic equilibrium. The calibration of this bias factor is informed by weak gravitational lensing estimates, with various constraints provided, such as (1−b) = 0.69±0.07, (1 − b) = 0.78 ± 0.08, and 1/(1 − b) = 0.99 ± 0.19. Additionally, the determination of cosmological parameters from Planck cluster counts relies on the mass bias parameter, with a derived constraint of (1 − b) = 0.62 ± 0.03. 1807.06209v4.pdf	The X-ray cluster masses errors are corrected by multiplying the true masses by a “hydrostatic mass bias” factor.

Simple_Different Same The parameter constraints from the DES galaxy correlation and lensing, along with the Planck 2018 results, are as follows:1. From the DES data alone (with a base-ΛCDM model and ∑mν = 0.06 eV):   - S8 = 0.793 ± 0.024   - Ωm = 0.256+0.023−0.0312. From the Planck results (TT,TE,EE+lowE+lensing):   - S8 = 0.832 ± 0.013   - Ωm = 0.315 ± 0.0073. When combining DES with the baseline Planck likelihood:   - S8 = 0.811 ± 0.011   - Ωm = 0.3040 ± 0.0060   - σ8 = 0.8062 ± 0.00574. The full joint DES likelihood reduces the error bars in the σ8–Ωm plane, resulting in only 95% confidence contours overlapping with Planck CMB data, indicating a moderate tension (approximately 2% PTE) between the two datasets. [8] 1807.06209v4.pdf	S_8 = 0.811 \pm 0.011,
\Omega_m = 0.3040 \pm 0.0060,
\sigma_8 = 0.8062 \pm 0.0057,

Simple_Different Different BAO measurements are utilized with significant importance in Planck papers because they serve as the primary non-CMB astrophysical data set, providing a robust geometrical test of cosmology. The acoustic scale measured by BAOs, approximately 147 Mpc, is much larger than the scale of virialized structures, making BAO measurements insensitive to nonlinear physics. This characteristic enhances their reliability compared to other non-CMB data. Furthermore, BAO results from galaxy surveys have consistently shown excellent agreement with the best-fit base-ΛCDM cosmology inferred from Planck, reinforcing their significance in cosmological studies. 1807.06209v4.pdf	The acoustic scale of BAO is much larger than that of virialzed strucutres. This scale makes it a robust test of cosmology and makes it sensitive to non-linear physics

Simple_Different Same The acoustic oscillations of the CMB power spectrum are primarily driven by the photon-baryon perturbations that occur at recombination. These oscillations correspond to a sharply-defined acoustic angular scale on the sky, which is determined by the comoving sound horizon at recombination (r∗) and the comoving angular diameter distance (DM). The relationship between these distances quantifies how far the perturbations can influence the CMB. 【4:0†source】	There is very strong evidence for purely adiabatic perturbations driving the acoustic oscillations.

Simple_Different Different No information given. No relevant sources.	The joint Planck+BAO result has an overall 2.3\sigma tension with the Ly \alpha BAOs result.

Simple_Different Same The mid-point redshift of reionisation, according to the Planck 2018 TT, TE, EE+ lowE analysis, is zre = 7.68 ± 0.79 (68% confidence level). 1807.06209v4.pdf	7.68 \pm 0.79

Simple_Different Same The differences in the bbCDM parameters between the Planck 2015 and 2018 releases are primarily due to two main effects:1. **New Polarization Low-` Likelihood**: The introduction of the new HFI low-` polarization likelihood, replacing the 2015 LFI likelihood, is the largest contributor to the shifts in parameters. This change led to a tighter constraint on the optical depth (τ), resulting in a decrease of ln(1010As) by 1σ through the Ase−2τ degeneracy. Consequently, this adjustment decreased the gravitational lensing smoothing at high multipoles, necessitating an increase of about 1σ in the cold dark matter density parameter (ωc). To maintain power, the spectral index (ns) shifted down by about 0.5σ, along with adjustments in the angular scale of the sound horizon (θ∗) and baryon density (ωb) by approximately 0.5σ.2. **Polarization Corrections in the High-` Likelihood**: Significant changes also arose from corrections applied to the polarization spectra. These corrections resulted in an increase in ωb by around 1σ, primarily due to beam-leakage corrections in the TE high-` likelihood. This adjustment also led to an increase of approximately 0.5σ in ns, compensating for the previous shift in ns due to the change in τ. Additionally, the beam-leakage correction affected ωc (decreasing it by −0.7σ) and θMC (increasing it by +0.7σ). Overall, these adjustments reflect the impact of improved data and methodologies in the analysis of cosmic microwave background polarization. [4:0†source]	A new polarization low-l likelihood and polarization corrections in the high-l likelihood. 

Simple_Same Same The high-multipole likelihoods in the Planck 2018 analysis are constructed from half-mission cross-spectra measured from the 100-, 143-, and 217-GHz HFI frequency maps. The multipoles used are in the range of 30 ≤ ` ≤ 2508 for TT and 30 ≤ ` ≤ 1996 for TE and EE. Specifically, the TT likelihood utilizes four half-mission cross-spectra with the following multipole cuts: - 100 × 100 (` = 30–1197)- 143 × 143 (` = 30–1996)- 143 × 217 (` = 30–2508)- 217 × 217 (` = 30–2508)For TE and EE likelihoods, additional cross-spectra are included to enhance the signal-to-noise ratio, with these multipole cuts:- 100 × 100 (` = 30–999)- 100 × 143 (` = 30–999)- 100 × 217 (` = 505–999)- 143 × 143 (` = 30–1996)- 143 × 217 (` = 505–1996)- 217 × 217 (` = 505–1996). 1807.06209v4.pdf	The 100-, 143-, and 217-GHz HFI frequency maps.

Simple_Same Same According to the Planck 2018 lowE analysis, the optical depth \( \tau \) is \( 0.0506 \pm 0.0086 \) with a 68% confidence level (CL). 1807.06209v4.pdf	0.0506 \pm 0.0086

Simple_Different Same The dominant effects of the CMB lensing on the CMB photons, as highlighted in the Planck 2018 paper, include: 1) a smoothing of the acoustic peaks, 2) conversion of E-mode polarization to B-mode polarization, and 3) generation of a connected 4-point function. These effects can be measured in high angular resolution, low-noise observations, such as those from Planck. 1807.06209v4.pdf	Smoothing of the acoustic peaks, conversion of E-mode polarization to B-mode polarization, and generation of a connected 4-point function

Simple_Different Different Yes, there is evidence of tensions between the Planck 2018 and the SPT determinations of cosmological parameters. Henning et al. (2018) noted a significant (>∼ 2σ) tension with the base-ΛCDM model, indicating that the parameters of the base-ΛCDM model tend to drift away from the Planck solution as the SPTpol likelihood is extended to higher multipoles. Additionally, the SPTpol data, particularly the TE+EE combined analysis, strongly disfavors the Planck ΛCDM cosmology, suggesting a notable discrepancy between the two datasets. 【6:3†source】, 【6:7†source】, 【6:0†source】	No evidence for any statistically significant inconsistency between the Planck and the SPT cosmological parameters.

Simple_Different Similar In the Planck 2018 paper, the differences in cosmological parameters between the low and high multipole likelihoods are significant. The high multipole results indicate a higher matter density and fluctuation amplitude, along with lower values for the spectral index (ns) and the Hubble constant (H0) compared to the low multipole range. Specifically, the high multipole likelihood predicts a CMB lensing amplitude parameter of σ8Ω0.25m = 0.649 ± 0.018. Additionally, the parameter Ωmh2 shows a notable difference between the two ranges, differing at the 2.8σ level. The internal tensions observed between these multipole ranges are thought to be consistent with moderate statistical fluctuations, particularly related to the low-` dip at large scales and its correlation with lensing amplitude on small scales. 1807.06209v4.pdf	\Omega_mh^2 differs between the low and high multipole likelihoods at approximately the 2\sigma level

Simple_Different Similar Yes, there are tensions between the results in the Planck 2018 paper and other datasets at more than the 2 sigma significance level. Specifically, the discrepancy with direct measurements of H0 is significant at about the 4.4 sigma level, according to the latest measurement from Riess et al. (2019). However, aside from this, other tensions are not significant at more than the 2–3 sigma level. [22:0†1807.06209v4.pdf]	Only the direct measurements of H_0 are inconsistent with the Planck results at the 2 \sigma level.

Simple_Same Same In the generation of the initial conditions in the CAMELS simulations, several assumptions are made:1. The initial conditions are generated at redshift z = 127 using second order Lagrangian perturbation theory (2LPT).2. It is assumed that the initial power spectra of dark matter and gas in the hydrodynamic simulations are the same and equal to that of total matter.3. The growth factor and growth rate are considered scale-independent, which allows for the use of standard rescaling codes.4. Cosmological parameters are fixed across all simulations: \(\Omega_b = 0.049\), \(h = 0.6711\), \(n_s = 0.9624\), \(M_ = 0.0 \, eV\), \(w = -1\), and \(\Omega_K = 0\).5. The parameters \(\Omega_m\) and \(\sigma_8\) are varied across simulations, with \(\Omega_m\) ranging from 0.1 to 0.5 and \(\sigma_8\) from 0.6 to 1.0, to mitigate prior effects on the output of neural networks.6. In the N-body simulations, the only parameters that change are \(\Omega_m\), \(\sigma_8\), and the initial random seed that determines the initial Gaussian density field. 2010.00619v2.pdf	That the initial power spectra of dark matter and gas in the hydrodynamic simulations are the same, and equal to that of total matter.

Simple_Same Same The spatial resolution for the IllustrisTNG model used in CAMELS is approximately 2 kpc comoving. 2010.00619v2.pdf	2 kpc comoving

Simple_Different Similar The main methodological difference between the wind velocity parametrizations used by the two galaxy formation models in CAMELS is that SIMBA's wind velocity is based on the FIRE model and scales with galaxy circular velocity, incorporating a specific formula that limits the wind kinetic energy to the available supernova (SNe) energy. This results in an attenuation of wind velocity when necessary. In contrast, CAMELS does not impose this constraint, allowing for greater flexibility and control over the galactic wind efficiency, which enables different parameter variations in the wind velocity normalization. [18] 2010.00619v2.pdf	In IllustrisTNG, v_w is calculated using dark matter velocity dispersion and the Hubble constant, while in SIMBA, v_w is calculated using the galaxy circular velocity.

Simple_Different Same In the CAMELS simulations, the parameters that are varied include six key cosmological and astrophysical parameters: \(\Omega_m\), \(\sigma_8\), and four astrophysical parameters (ASN1, ASN2, AAGN1, and AAGN2) that control the strength of stellar and AGN feedback. The variations are implemented in different ways across several sets of simulations:1. **Latin Hypercube (LH) Set**: In this set, all six parameters (\(\Omega_m\), \(\sigma_8\), ASN1, ASN2, AAGN1, AAGN2) are varied simultaneously.2. **1P Set**: This consists of 61 simulations where each parameter is varied one at a time, while keeping the random seed constant across all simulations.3. **CV Set**: This includes 27 simulations that share the same values for the cosmological and astrophysical parameters, differing only in their initial random seed.4. **EX Set**: This set contains 4 simulations where the cosmological parameters are held constant, but the astrophysical parameters vary. 2010.00619v2.pdf	4 different simulation sets are run in CAMELS, which vary the parameters andd initial conditions differently. (LH) varies all parameters and has different inital seeds, (1P) has the same initial random seed, where only one paramter is varied at a time, (CV) fixes the parameters and has different initial random seeds and (EX) represents extreme feedback with fixed initial random seeds.

Simple_Same Same The softening length for the N-body simulations in CAMELS is set to 0.5 h−1 kpc. 2010.00619v2.pdf【4:0†source】	0.5 h^{-1}kpc

Simple_Different Same CAMELS quantifies the difference between cosmological/astrophysical parameter variations and random variations in the initial conditions by analyzing the contributions of cosmic variance and changes in cosmological and astrophysical parameters to the range of variation in measured quantities. Specifically, it assesses what fraction of the variation is due to cosmic variance versus changes in cosmology and astrophysics. The findings indicate that on large scales, cosmic variance dominates the range of variation, while on small scales, variations in cosmological and astrophysical parameters have a greater impact. This distinction helps in understanding the sources of variation in the matter power spectrum. 2010.00619v2.pdf	They compute the median and 16-84 percentiles of the IllustrisTNG LH and CV sets.

Simple_Different Different The systematic differences between the IllustrisTNG and SIMBA suites in CAMELS include:1. **Halo Temperatures**: Halo temperatures at fixed mass are systematically higher in SIMBA compared to IllustrisTNG.2. **Galaxy Sizes**: SIMBA galaxies are generally larger than those in IllustrisTNG, except for galaxies with low stellar masses.3. **Variation Range**: The range of variation in the SIMBA simulation set is generally smaller than that in IllustrisTNG.4. **Black Hole Mass Variation**: For stellar masses less than 5 × 10^10 h−1M⊙, the range of variation in black hole mass is larger in IllustrisTNG, while at higher masses, the ranges are comparable.5. **Baryon Fractions**: The baryon fractions in SIMBA are consistently lower than those in IllustrisTNG. 1. 2010.00619v2.pdf【4:0†source】2. 2010.00619v2.pdf【4:4†source】3. 2010.00619v2.pdf【4:4†source】4. 2010.00619v2.pdf【4:3†source】5. 2010.00619v2.pdf【4:7†source】	The systematic differences are in the gas power spectra and the baryon fractions

Simple_Different Same The systematic differences between the IllustrisTNG and SIMBA suites in CAMELS can be attributed to several key factors:1. **Intrinsic Differences in Galaxy Models**: There are large intrinsic differences between the galaxies produced by the SIMBA and IllustrisTNG simulations. Although both exhibit a similar qualitative dependence on the matter density parameter (Ωm), they occupy the parameter space differently due to the distinct subgrid models used in each simulation suite.2. **Baryon Fractions**: The baryon fractions in the SIMBA simulations are consistently lower than those in the IllustrisTNG simulations, indicating a fundamental difference in how baryonic matter is treated in each model.3. **Astrophysics Parameters**: The astrophysical parameters in the two suites have very different meanings, which contributes to the differences in their outputs and behaviors.4. **Model Robustness**: The differences in galaxy properties lead to a lack of robustness in models trained on one suite when tested on the other. A model trained on IllustrisTNG properties does not perform well when applied to SIMBA galaxies, and vice versa. 1. 2201.02202v1.pdf2. 2010.00619v2.pdf	The reasons for the systematic differences in the gas power spectra and the baryon fractions are the different subgrid feedback implementations and effective feedback strengths and the different feedback implementations and parameter variations, respectively.

Simple_Different Same In the CAMELS project, the following machine learning tasks utilize different types of learning models:**Supervised Learning Models:**1. Emulator - Predicts average SFRD from parameters.2. Parameter Regression - Constrains parameter values from measurements of the SFRD.3. Symbolic Regression - Approximates the mean SFRD with analytic expressions.**Unsupervised Learning Models:**1. Data Generation - Generates 2D gas temperature maps using generative adversarial networks.2. Dimensionality Reduction - Finds lower dimensionality representation of 2D gas maps using convolutional auto-encoders.3. Anomaly Detection - Identifies anomalies in 2D gas maps using convolutional auto-encoders. 2010.00619v2.pdf	The emulator, parameter and symbolic regression are all handled by supervised learning models and the data generation, dimensionality reduction and anomaly detection are all handled by unsupervised learning models.

Simple_Different Different The neural network of CAMELS can predict the evolution of a cosmological quantity, specifically the Star Formation Rate Density (SFRD), with an error of δ = 0.12 dex when using cosmological and astrophysical parameters. This indicates a reasonable level of accuracy in its predictions. Additionally, the models maintain similar accuracy and precision across different redshifts, with a slight improvement noted at higher redshifts. Therefore, the network demonstrates a competent ability to predict cosmological quantities as a function of redshift. 1. 2010.00619v2.pdf2. 2201.02202v1.pdf3. 2201.02202v1.pdf	The neural network achieves an approximate error rate of 30% for training data that contains 20% "error"/scatter due to cosmic variance.

Simple_Different Similar No information. No relevant sources.	Complexity is an integer number associated to each operator, which penalises more complex operations in the functions

Simple_Different Similar Based on the provided information, the neural networks perform better than the symbolic regression equations in modeling the evolution of cosmological quantities with redshift in the CAMELS results. The neural network achieved a δ = 0.106 error, while the equations achieved approximately 45% accuracy compared to the neural network's 30% accuracy. Therefore, the neural networks are better at modeling these quantities. 1. 2010.00619v2.pdf  2. 2201.02202v1.pdf  3. 2201.02202v1.pdf	While the neural network has a lower \delta error than the symbolic regression equation, the equations are generally more robust in extrapolations and can help in understanding the physics behind the cosmological processes.

Simple_Different Same In CAMELS, the architecture of the unsupervised generative models involves a generator and a discriminator. The generator's mission is to create images that possess the same properties as real images, while the discriminator's role is to differentiate between real and fake images. As the discriminator becomes more adept at its task, it challenges the generator to improve its output. This dynamic creates a feedback loop where the generator is compelled to produce better images in each iteration to successfully deceive the increasingly skilled discriminator. 【6:0†source】	There are two networks present in the generative model: the generator and the discriminator. The former generates data that has the same properties as the original data and the latter tries to distinguish the difference between the original data and the generated data. This adverserial dynnamic produces better data on each iteration.

Simple_Different Same The fake data generated by the GANs in CAMELS is highly representative of the real data. The images produced by the GAN are described as looking very realistic and almost indistinguishable from the real ones. Quantitatively, there is an excellent agreement between the results from the real and fake images, with results agreeing at approximately the 15% level across scales from k = 1 hMpc−1 to k = 30 hMpc−1. Additionally, there is also an excellent agreement of about 25% between both distributions over nearly four orders of magnitude in temperature. This strong correlation suggests that the GANs are effective and not significantly affected by mode collapse. 2010.00619v2.pdf	The results from the real and fake images agree at (approximately) the 15% level for the temperature power spectrum and at (approximately) the 25% level for the temperature PDF. 

Simple_Different Same The maximum reconstruction error for the autoencoder in CAMELS is around 1.3× 10−3. 2010.00619v2.pdf	1.3\times10^{-3}

Simple_Different Same The surprising behavior exhibited by the CAMELS autoencoder after training is that it has learned to compress general images, allowing it to reconstruct any image regardless of its nature. This outcome is not aligned with the intended goal, which was to find a lower dimension manifold that captures the specific structure of the data. [4] 2010.00619v2.pdf	Even though the autoencoder was trained on temperature maps with fixed cosmology/astrophysics, it was able to accurately reconstruct temperature fields with different cosmologies/astrophysics.

Simple_Different Same No information. 	To verify this, the authors of the CAMELS paper gave the autoencoder an image without any kind of cosmology or astrophysics data: the CAMELS logo. The error of reconstruction of 70% of the encoded images of the CAMELS logo was higher than any of the errors for the temperature maps.

Simple_Different Same The main limitations of the CAMELS simulations include:1. **Mass and Spatial Resolution**: CAMELS cannot resolve scales below approximately 1 h−1 kpc, and only halos with a dark matter mass above 6.5 × 10^9(Ωm − Ωb)/0.251 h−1 M⊙ contain at least 100 dark matter particles, which restricts the detail of smaller structures.2. **Volume of Simulations**: The simulations have a relatively small volume of (25 h−1 Mpc)³, which means that long wavelength modes are not included. This is significant for the formation of large structures like galaxy clusters and for accurately normalizing the matter power spectrum across all scales.3. **Parameter Variability**: CAMELS is limited to variations of only two cosmological parameters and four astrophysical parameters, which restricts the range of scenarios that can be explored.4. **Applicability**: Despite being the largest set of cosmological (magneto-)hydrodynamic simulations with full galaxy formation physics, CAMELS has limitations in its applicability for analyzing cosmological data across different regimes. 2010.00619v2.pdf	The mass and spatial resolution in CAMELS does not allow for resolution of scales below \approx 1 h^{−1}kpc. The volume of the simulations is relatively small: (25 h^{−1}Mpc)^3. CAMELS is limited to variations of only two cosmological parameters and four astrophysical parameters.

Simple_Different Different In the EX set of the SIMBA simulations, the parameters that are varied are: 1) very efficient supernova feedback, 2) very efficient AGN feedback, and 3) no feedback. One simulation uses fiducial values, while the other three represent these extreme cases. 2010.00619v2.pdf	A_{SN1}, A_{SN2}, A_{AGN1}, A_{AGN2}

Simple_Different Same In the CAMELS framework, the A_{AGN1} parameter is used to vary the total momentum flux associated with the low accretion rate kinetic feedback from supermassive black holes (SMBHs). It modulates the feedback mechanism by adjusting the overall energy and speed normalizations, influencing how SMBH feedback affects the surrounding environment in the IllustrisTNG simulations. 2010.00619v2.pdf	Kinetic mode BH feedback: energy per unit BH accretion rate

Simple_Different Same In the "Cosmology with one galaxy?" paper, the simulations used to simulate the galaxies are from the CAMELS project, which includes two different suites of hydrodynamic simulations: 1. **IllustrisTNG**, which uses the AREPO code. 2. **SIMBA**, which uses the GIZMO code. 2201.02202v1.pdf	Galaxies from the simulations of the CAMELS project are used, with two different suites of hydrodynamic simulations: IllustrisTNG, run with the AREPO code, and SIMBA, run with the GIZMO code. The SIMBA simulation has been extended with the addition of supermassive black hole growth and feedback.

Simple_Different Different The simulations in the "Cosmology with one galaxy?" paper follow the evolution of 2×2563 dark matter plus fluid elements in a periodic comoving volume of (25 h−1Mpc)³ from redshift z = 127 down to z = 0. 2201.02202v1.pdf	All simulations follow the evolution of 2\times253^3 dark matter plus fluid elements in a periodic comoving volume of (25 h^{−1}Mpc)^3 from z = 127 down to z = 0.

Simple_Different Same In the "Cosmology with one galaxy?" paper, the fixed initial parameters for the simulations are as follows: - Ωb = 0.049 - h = 0.6711 - ns = 0.9624 - ∑mν = 0.0 eV - w = −1. Additionally, while each simulation has different values of Ωm and σ8, the hydrodynamic simulations also vary four astrophysical parameters related to supernova and AGN feedback: ASN1, ASN2, AAGN1, and AAGN2. 2201.02202v1.pdf	All simulations fix the value of these parameters: \Omega_b = 0.049, h = 0.6711, n_s = 0.9624, \sum m_{\nu} = 0.0 eV, w = −1.

Simple_Different Different In the "Cosmology with one galaxy?" paper, the direct comparison of the performance of the IllustrisTNG and SIMBA simulations is performed by training neural networks to infer cosmological and astrophysical parameters from galaxies at redshifts 1, 2, and 3. After training, the models are tested on individual galaxies from the test set of each simulation. The average posterior mean and posterior standard deviation are computed for all galaxies in a given simulation. The results indicate that while both models show similar accuracy and precision across redshifts, the models trained on IllustrisTNG galaxies demonstrate better accuracy and precision compared to those trained on SIMBA galaxies, attributed to the inclusion of three additional features in the IllustrisTNG simulations. 2201.02202v1.pdf	There is no correspondence between simulations among the IllustrisTNG and the SIMBA sets. Thus, a direct comparison between the two is not performed.

Simple_Different Different In the "Cosmology with one galaxy?" paper, galaxies are defined by various internal properties, including stellar mass, gas metallicity, and star-formation rate. 2201.02202v1.pdf	Galaxies are defined as subhalos that contain more than 20 star particles.

Simple_Different Different In the "Cosmology with one galaxy?" paper, the properties of the galaxies that are tracked include the stellar mass, star-formation rate, total mass in the galaxy’s subhalo, stellar radius, stellar metallicity, and maximum circular velocity. 2201.02202v1.pdf	Galaxies from all simulations are characterised by the following properties: M_g (the gas mass content of the galaxy, including the contribution from the circumgalactic medium), M_{BH} (the black-hole mass of the galaxy.), M_* (the stellar mass of the galaxy), Z_g (the mass-weighted gas metallicity of the galaxy), Z_* (the mass-weighted stellar metallicity of the galaxy), SFR. (the galaxy star-formation rate) and R_* (the radius containing half of the galaxy stellar mass). For galaxies of the IllustrisTNG simulations, the following properties are also tracked: U (the galaxy magnitude in the U band), K (the galaxy magnitude in the K band) and g (the galaxy magnitude in the g band).

Simple_Different Same No information. No relevant sources.	For the gradient boosting trees, the hyperparameters are the learning rate, the maximum depth, the minimum child weight, the value of gamma, the colsample bytree and the number of estimators. For the neural networks, the hyperparameters are the number of fully connected layers, the number of neurons in each layer, the dropout value, the value of the weight decay and the value of the learning rate. In both, the hyperparameter space is searched to minimise the value of the loss function.

Simple_Different Same The neural network can predict the cosmological parameter Ωm with varying levels of accuracy and precision depending on the dataset used. For a single galaxy, it infers Ωm with a precision of approximately 10%. When considering SIMBA and IllustrisTNG galaxies, the model achieves an accuracy of about 0.037 and a precision of 12%. Additionally, it can infer Ωm for most galaxies in a simulation with an accuracy of 0.034 and a precision of 10.5%. The performance remains consistent across different redshifts, with slight improvements noted at higher redshifts. Cosmology with one galaxy? 2201.02202v1.pdf	The network has not found enough information to infer the value of A_{AGN1}, A_{AGN2}, and \sigma_{8}, so it just predicts the mean value with large errorbars for these parameters. For the supernova parameters, A_{SN1} and A_{SN2}, the network provides some loose constraints . On the other hand, for \Omega_m, the network seems to have found enough information to infer its value, from the properties of individual galaxies, with an (approximate) 10% precision.

Simple_Different Same In the "Cosmology with one galaxy?" paper, the neural network can infer the value of \( \Omega_m \) with an average accuracy of 0.034 and a precision of 10.5%. 2201.02202v1.pdf	On average for all galaxies, the network is able to infer the value of \Omega_m with an accuracy
of 0.034 and a 10.5% precision

Simple_Different Same In the "Cosmology with one galaxy?" paper, the significance of how the neural network infers the value of \( \Omega_m \) lies in its ability to achieve a precision of approximately 10% and an accuracy of 0.034. This indicates that the model can effectively utilize the properties of individual galaxies to estimate \( \Omega_m \ \) with notable reliability. Furthermore, the inference process is believed to be influenced by the dark matter content of galaxies, suggesting that the network may be leveraging information related to either the dark matter or the gravitational potential well of the galaxy. Cosmology with one galaxy? 2201.02202v1.pdf	The neural network provides evidence showing that the value of \Omega_m can be inferred from the properties of individual galaxies, for the vast majority of the cases. This holds for galaxies with a wide range of different cosmological and astrophysical properties.

Simple_Different Same The inferences of the neural network regarding the value of Ωm from a single galaxy are somewhat relevant but limited. The models can achieve about 10% precision in inferring Ωm when internal properties of a single galaxy are known, but they struggle with robustness due to variations in subgrid physics and intrinsic differences in galaxy properties across different simulation models. Specifically, while certain properties like stellar mass, stellar metallicity, and maximum circular velocity are important for determining Ωm, the models fail to accurately infer Ωm from galaxies that are not part of the same simulation suite. Therefore, while the neural network can provide some insights, its applicability to real galaxies is constrained by these factors. Cosmology with one galaxy? 2201.02202v1.pdf	When the neural network is tested on galaxies from simulations different to the ones used for training, the model is not able to infer the correct cosmology in most of the cases. This indicates that the model is not robust and may be using information that is specific to each galaxy formation model, limiting the relevance of these inferences to real galaxies. 

Simple_Different Different In the "Cosmology with one galaxy?" paper, the most important galaxy properties that the neural network uses for the inference of \( \Omega_m \) are stellar mass, stellar metallicity, and maximum circular velocity. 2201.02202v1.pdf	The most important properties appear to be V_{max} and M_{*} for both IllustrisTNG and SIMBA galaxies. The stellar metallicity and stellar radius are also among the five most important features in both cases. However, for IllustrisTNG galaxies, the K-band is very important, while in the case of SIMBA galaxies, R_{max}, is selected as an important feature. However, it is important to note that this analysis was done with gradient boosting trees rather than with the neural networks, as neural networks are too computationally expensive.

Simple_Different Same The trained models in the "Cosmology with one galaxy?" paper are not robust because they perform well only when tested on galaxies from the same subgrid model used for training. Specifically, a model trained on galaxy properties from IllustrisTNG simulations fails when tested on SIMBA galaxies, and vice versa. This indicates that the models may be learning specific characteristics of each simulation or that the two simulations do not overlap in parameter space. 2201.02202v1.pdf	Plotting the data from the IllustrisTNG and SIMBA simulations in a lower dimensional space, where the most important properties are considered, reveals that the two simulations populate the parameter space differently, depending on \Omega_m. According to the authors, this is why the models are not robust, as this indicates that \Omega_m induces an effect on galaxy properties

Simple_Different Same In the "Cosmology with one galaxy?" paper, the parameter m influences the placement of the galaxy in parameter space because it affects the dark matter content of galaxies. Different values of m lead to distinct manifolds where galaxy properties reside. This means that for varying values of m, the characteristics of galaxies will differ significantly, making it challenging to replicate the properties of real galaxies if the cosmological model's m deviates significantly from the true value. Thus, the change in m alters the galaxy's position in the parameter space due to its impact on the underlying physics of galaxy formation and evolution. 2201.02202v1.pdf	The authors interpret these results as \Omega_m changing the manifold where galaxy properties reside, indicating that \Omega_m  induces an effect on galaxy properties that cannot be mimicked by astrophysical effects.

Simple_Different Same V_{max} is considered an important variable to infer \( \Omega_m \) because it increases monotonically with \( \Omega_m \). This means that as \( \Omega_m \) increases, indicating a greater dark matter density in the Universe, the gravitational potential well of galaxies is enhanced, leading to higher values of V_{max}. Additionally, V_{max} is shown to contain more information than other variables such as total subhalo mass or velocity dispersion, which are also influenced by dark matter. The critical role of V_{max} is further emphasized by the fact that removing it from the analysis cancels the constraining power for inferring \( \Omega_m \), underscoring its significance in understanding the dark matter content of galaxies. 2201.02202v1.pdf	In plots of V_{max} versus M_*, for a fixed value of the stellar mass, the larger the dark matter mass the higher the value of V_{max}. This is the same trend is found with \Omega_m, indicating that larger values of \Omega_m will tend to increase the dark matter content of galaxies. Thus, according to the authors, \Omega_m increases the dark matter content of the galaxies, which, in turn, increases the value of V_{max} for fixed stellar masses.

Simple_Different Same In the "Cosmology with one galaxy?" paper, the authors test if the neural network uses information concerning dark matter in galaxies by analyzing the performance of models trained with different sets of features. They specifically note that when using features that exclude Vmax, the accuracy of the model in inferring the matter density parameter Ωm significantly degrades—by 100% and 43% for different configurations. This indicates that Vmax contains critical information that is not captured by other variables like Mt and σv. Furthermore, they conclude that Vmax is essential for inferring Ωm, suggesting that the network may be utilizing information related to the dark matter content of the galaxy or its gravitational potential well. Additionally, they observe that at fixed stellar mass, Vmax increases with both Ωm and the dark matter mass (Mdm), supporting the idea that a higher Ωm correlates with increased dark matter content, which in turn enhances Vmax. 2201.02202v1.pdf	The authors trained networks on galaxies from the IllustrisTNG simulations using all properties except V_{max}, \sigma_{\nu}, M_t, R_t, and R_{max}, which are quantities that are expected to receive large contributions from the dark matter component of galaxies. The network trained with this configuration is still able to infer the value of \Omega_m but with much lower accuracy. Thus, the authors conclude that the network may be using information either about the dark matter content of the galaxy or about its gravitational potential well. 

Simple_Different Same In the "Cosmology with one galaxy?" paper, the dark matter mass (Mdm) is calculated using the formula: Mdm = Mt − Mg − M∗ − MBH, where Mt is the total mass, Mg is the gas mass, M∗ is the stellar mass, and MBH is the black hole mass. Additionally, the total matter mass contained within a radius Rmax is given by Mmax = Vmax^2 Rmax/G. 2201.02202v1.pdf	The dark matter mass is computed as M_t − M_g − M_* − M_{BH}

Simple_Different Same The neural network in the "Cosmology with one galaxy?" paper prefers to use V_{max} over other properties like the galaxy’s subhalo total mass (M_{tot}) or velocity dispersion (σ_{v}) because using these other variables significantly degrades the model's accuracy on Ω_{m}—by 100% for M_{tot} and 43% for σ_{v}. This suggests that V_{max} contains more relevant information. Additionally, V_{max} is believed to correlate more strongly with stellar mass than with subhalo mass and remains stable as it probes the mass in the inner regions of the subhalo, which are less influenced by tidal forces that can alter the dark matter content of galaxies. Therefore, the neural network likely focuses on the dark matter or total mass content in the central region of galaxies, rather than the total dark matter mass in the subhalo. 2201.02202v1.pdf	V_{max} contains more information than M_t and \sigma_{\nu}, which are other properties that are expected to be heavily affected by dark matter. The authors believe that is because it is known that V_{max} correlates more strongly with stellar mass than with subhalo mass, thus the value of V_{max} may remain rather stable since it mostly probes the mass in the inner regions of the subhalo, that are the least affected by processes like tidal forces.

Simple_Different Same Yes, the paper indicates that while they could not identify a specific process that would lead to numerical artifacts affecting the inference of \( \Omega_m \), they also cannot completely rule out the possibility that the results may reflect nonphysical information arising from numerical artifacts. 2201.02202v1.pdf	The authors do not refute the possibility of numerical artifacts that can be learned by the neural network, but they also cannot come up with a process that could give rise to such a numerical artifact.

Simple_Different Similar If the authors' conclusions in the "Cosmology with one galaxy?" paper are correct, the expected consequences would be that galaxy properties will exist in distinct manifolds depending on the value of Ωm. This suggests that it would be challenging, if not impossible, to accurately reproduce the properties of real galaxies when using cosmological models with an Ωm value that significantly deviates from the true value. This prediction can be tested through hydrodynamical simulations or semi-analytic models. 2201.02202v1.pdf	If the conclusions given in the "Cosmology with one galaxy?" are correct, it implies that it should be difficult, if not impossible, to reproduce the galaxy properties from real galaxies for cosmologies with a value of \Omega_m far away from the true one. Also, galaxy properties are known to exhibit some level of intrinsic stochasticity in numerical simulations. So, this will imply that either the manifold containing the galaxy properties will have some intrinsic tightness, or that galaxies affected by this effect will move along the manifold.

Simple_Different Same In the "Cosmology with one galaxy?" paper, the ranges for the parameters that are allowed to vary between simulations are as follows: 1. Ωm ∈ [0.1, 0.5] 2. σ8 ∈ [0.6, 1.0] 3. ASN1, AAGN1 ∈ [0.25, 4.0] 4. ASN2, AAGN2 ∈ [0.5, 2.0] 2201.02202v1.pdf	\Omega_m \in [0.1, 0.5] 
\sigma_8 \in [0.6, 1.0]
A_{SN1}, A_{AGN1} \in [0.25, 4.0]
A_{SN2}, A_{AGN2} \in [0.5, 2.0]

Simple_Different Same The relationship between \( \Omega_m \) and other galaxy properties cannot be modeled as linear relationships. The tests indicate that \( \Omega_m \) does not correlate simply with a single property, and knowing astrophysical parameters does not significantly improve predictions. Instead, \( \Omega_m \) appears to change the manifold of galaxy properties in a way that is distinct from changes induced by feedback, suggesting that the correlations are not linear. 2201.02202v1.pdf	No, \Omega_m cannot be inferred using linear models.

Simple_Different Same The SH0ES program looked for the following qualities in type Ia supernovae (SNe Ia) to ensure reliable calibration of their fiducial luminosity: 1) modern photometric data (photoelectric or CCD), 2) observations made before maximum brightness and well thereafter, 3) low reddening (AV < 0.5 mag), 4) spectroscopically typical characteristics, and 5) a strong likelihood of detecting Cepheids in the host galaxy with HST. 1604.01424v3.pdf	Modern photometric data, observed before maximum brightness and well thereafter, low reddening (implying AV < 0.5 mag), spectroscopically typical, and a strong likelihood of being able to detect Cepheids in its host galaxy with HST.

Simple_Different Similar To retrieve unbiased Cepheid photometry data from the model of the Cepheid and nearby sources, two main approaches can be utilized. First, one can recalculate the Cepheid photometry using the original mean sky, or second, correct the overestimate of Cepheid flux based on the measured photometry of artificial stars added to the scenes. The artificial star method has the added benefit of providing an empirical error estimate and an estimate of outlier frequency. When measuring photometry in crowded regions, it is crucial to account for source blending, which can distort the statistics of the Cepheid background. Typically, the mean flux of pixels in an annulus around the Cepheid is subtracted from the measured flux at the Cepheid's position to achieve unbiased photometry. Additionally, improving the precision of Cepheid photometry can be accomplished by accurately attributing some flux to other overlapping sources in the scene. 1604.01424v3.pdf	Can either recalculate the Cephid photometry using the original mean sky or correct the overestimate of Cephid flux based on measured photometry of artificial stars added to the scene.

Simple_Different Different No information given. 	2962 seconds

Simple_Different Similar The leading source of scatter in the observed P–L relations of the SN hosts for the HST is the uncertainty in the Cepheid background, primarily due to blending. This blending results in a mean dispersion of 0.36 mag for the SN hosts, making it the dominant source of dispersion. 1604.01424v3.pdf	Uncertainty  in the Cephid background

Simple_Different Similar Blending has a symmetric effect on the NIR Wesenheit magnitude, specifically mW_I, compared to mW_H. This is due to the combination of blue blends, which cause mW_I to appear faint, and red blends, which make it appear bright. While the overall impact of blending on mW_I is generally small, it introduces significant uncertainty, which is the primary source of dispersion, averaging 0.36 mag for supernova hosts. This level of uncertainty is comparable to the impact and scatter observed for mW_H. 1604.01424v3.pdf	The blending largely cancels

Simple_Different Same Blending has a symmetric effect on the optical Wesenheit magnitude, specifically mW_I, compared to mW_H. The blending involves a mixture of blue blends, which make mW_I faint, and red blends, which make it bright. Although the overall impact of blending on mW_I is typically small, it introduces significant uncertainty, resulting in a mean dispersion of 0.36 mag for supernova (SN) hosts. This uncertainty is similar to that observed for mW_H. Additionally, there is a small mean difference of 0.025 mag (bright) for mW_I among SN hosts, with a host-to-host dispersion of 0.03 mag. If this blending effect is not corrected, it could lead to a 1% underestimate of distances and an overestimate of the Hubble constant (H0) in studies relying solely on mW_I. 1604.01424v3.pdf	Results in a mean difference of 0.025 mag and a host-to-host dispersion  of 0.03 mag. 

Simple_Same Same If the effect of blending on the Wesenheit magnitudes was not corrected, it would result in a 1% underestimate of distances. Consequently, this would lead to an overestimate of the Hubble constant (H0) for studies that rely exclusively on mW_I. 1604.01424v3.pdf	1% underestimate of distances.

Simple_Different Unsure To find the median difference in the optical Wesenheit magnitude for host N3972, we first need to identify the relevant values provided. The numbers given are: 79, 68, 7, 25, 0.18, 0.17, 0.07, and 0.38. However, the context does not specify which of these values represent the optical Wesenheit magnitudes or how they relate to each other to calculate a median difference. Since there is no clear indication of which values to use for the calculation of the median difference, I do not have enough information to answer the question. {1604.01424v3.pdf}	25 mmag

Simple_Same Same After the global outlier rejection, 63 Cepheid variable stars were considered in the analysis from the N3370 galaxy. 【10:0†source】	63

Simple_Different Same The contributions to the overall statistical error of the Cepheid-based distance measurements for the Hubble Space Telescope (HST) include:1. **NIR Sky Background Fluctuations (σsky)**: The largest source of measurement uncertainty arises from fluctuations in the near-infrared (NIR) sky background due to variations in blending, with a mean value of 0.28 mag.2. **Color Term Uncertainty (σct)**: This contributes an uncertainty of 0.07 mag, as determined from artificial star tests in the optical data.3. **Intrinsic Dispersion (σint)**: There is an intrinsic dispersion due to the nonzero temperature width of the Cepheid instability strip, which is 0.08 mag for mW_H.4. **Phase Error (σph)**: The use of random or limited-phase F160W magnitudes introduces an error of 0.12 mag, as shown by Monte Carlo sampling.The total statistical uncertainty (σtot) is calculated as the quadrature sum of these four terms: σtot = (σ²_sky + σ²_ct + σ²_int + (fphσph)²)^(1/2). 1604.01424v3.pdf	 NIR photometric error, color error, intrinsic width and random-phase

Simple_Different Same The apparent magnitude of the reference SN Ia is determined by expressing the magnitudes in the calibrator sample as m0x,i = (µ0,i − µ0,N4258) + m0x,N4258. Here, m0x,i represents the maximum-light apparent x-band brightness of a SN Ia in the ith host at the time of B-band peak, which is corrected for fiducial color and luminosity. This value is derived from the multiband light curves of each SN Ia using a light-curve fitting algorithm, specifically SALT-II. 1604.01424v3.pdf	The simultaneous fit to all Cepheid and SN Ia data to the equations m^W_{H,i,j} =(\mu_{0,i}−\mu_{0,N4258})+zp_{W,N4258}+b_W log P_{i,j}+Z_W \Delta log (O/H)_{i,j} and m^0_{x,i} = (\mu_{0,i} − \mu_{0,N4258}) + m^0_{x,N4258}, results in the determination of m^0_{x,N4258}, which is the expected reddening-free, fiducial, peak magnitude of a SN Ia appearing in NGC 4258.

Simple_Different Same The value of the Hubble constant calculated using only the maser distance as an anchor is 72.25 ± 2.38 km s−1 Mpc−1. 1604.01424v3.pdf	72.25 \pm 2.38 km s^{-1} Mpc^{-1}

Simple_Different Same The value of the Hubble constant (H0) calculated using both the maser distance and the parallaxes as anchors is H0 = 74.04 ± 1.74 km s−1 Mpc−1. 1604.01424v3.pdf	74.04 \m 1.74 km s^{-1} Mpc^{-1}

Simple_Different Similar The HST paper considers the following distances as possible anchors to calculate H_0: 1. Masers in NGC 4258 2. Parallaxes to Milky Way Cepheids 3. Detached Eclipsing Binaries (DEBs) in the Large Magellanic Cloud (LMC) 4. DEBs in M31 Additionally, M31 can also be used as an anchor by utilizing DEB-based distance estimates. 1604.01424v3.pdf	Trigonometric parallaxes to Milky Way Cephid variable stars, distance to the LMC using DEBs, distance to M31 using DEBs and distances to NGC4258 using water megamasers.   

Simple_Different Same The anchor distances that had problems in the determination of H_0 in the HST paper include M31. The issues with using M31 as an anchor stem from several obstacles, including the lack of appropriate filter data from the PHAT HST program, the need to recalibrate colors for measuring reddenings of M31 Cepheids, and significant systematic uncertainties in the DEB distances for early-type stars in M31. Consequently, M31 was removed from the anchor set of the primary fit to avoid unwarranted adjustments that could misrepresent the data. 1604.01424v3.pdf	The distance to M31 had problems with being used as an anchor in the determination of H_0.

Simple_Different Same M31 faces several obstacles in being used as an anchor for determining H_0 in the HST paper. Firstly, the PHAT HST program did not utilize the F555W filter or include time-series data, which limits the ability to deredden the Cepheids in F160W using the same methods applied to other SH0ES galaxies. Instead, the best available color for measuring the reddenings of the M31 Cepheids is F110W−F160W, necessitating recalibration to match the reddening in the V−I data. Additionally, the distances for early-type stars in M31, which are the only ones currently measured, involve significant systematic uncertainties due to non-LTE stellar model atmospheres. These factors complicate the use of M31 as a reliable anchor for H_0. 1604.01424v3.pdf	The PHAT HST program, which gathered the relevant data, did not use the F555W filter or include time-series data so the individual mean-light F555W-F814 colours cannot be used to deredden these Cephids. The colours would have to be recalibrated.

Simple_Different Different The final value of H_0 quoted in the HST paper, as the most reliable one without including systematic errors, is 73.24 ± 1.74 km s−1 Mpc−1. 1604.01424v3.pdf	73.24 \pm 1.59 km s^{-1} Mpc^{-1}

Simple_Different Same The full dataset used by the HST paper to calculate their final value for H_0 includes four sets of geometric distance calibrations of Cepheids: (i) megamasers in NGC4258, (ii) 8 detached eclipsing binaries (DEBs) in the Large Magellanic Cloud (LMC), (iii) 15 Milky Way (MW) Cepheids with parallaxes measured with HST/FGS, HST/WFC3 spatial scanning and/or Hipparcos, and (iv) 2 DEBs in M31. The Hubble constant values from these datasets are: 72.25±2.51, 72.04±2.67, 76.18±2.37, and 74.50±3.27 km s−1 Mpc−1, respectively. The best estimate of H0 = 73.24 ± 1.74 km s−1 Mpc−1 combines the anchors NGC4258, MW, and LMC. 1604.01424v3.pdf	 >2200 Cepheids (∼ 1000 in SN hosts), 19 SNe Ia, 15 MW parallaxes, the DEB-based distance to the LMC, and the maser distance to NGC 4258

Simple_Same Same The optical Wesenheit magnitude measurements have larger systematic errors compared to the NIR counterparts, with a systematic error of 2.8% for the optical Wesenheit. This is considerably worse than the NIR measurements and is also larger than the statistical error. The increased sensitivity of the optical Wesenheit to factors such as reddening, metallicity, and P–L relation breaks contributes to these larger systematic errors. 1604.01424v3.pdf	Optical Wesenheit

Simple_Different Same The large difference between the optical and NIR Wesenheit magnitude systematic errors in the HST paper can be attributed to several factors. The systematic error in the optical is 2.8%, which is significantly worse than the NIR counterpart and exceeds the statistical error. This discrepancy arises because variations in the treatment of reddening, metallicity, the period-luminosity (P–L) relation, and outlier rejection have a more pronounced effect on the optical Wesenheit magnitudes compared to the NIR ones. For instance, changes in the reddening law lead to larger shifts in the H0 value for optical magnitudes than for NIR magnitudes, with variations causing changes of up to 3.82 km s−1 Mpc−1 for optical data versus much smaller changes for NIR data. Additionally, adjustments to the P–L relation formulation also result in greater changes for optical measurements than for NIR, indicating that the optical data is more sensitive to these factors. 1604.01424v3.pdf	Changes to the treatment of reddening, metallicity, P–L relation breaks, and outlier rejection cause larger changes in H_0 for the optical than for the NIR Wesenheit magnitude calculations.

Simple_Different Different No information. No relevant sources.	3.4\sigma

Simple_Different Same The ACT DR6 power spectra improve white noise levels over previous results by roughly a factor of three in polarization and a factor of two in temperature compared to the Planck results. 2503.14454v1.pdf	ACT DR6 power spectra white noise levels improve over those of Planck by roughly a factor of 3 with polarization and a factor of two in temperature.

Simple_Different Different The signal-to-noise ratio of the CMB lensing of the ACT DR6 data, when combined with Planck NPIPE lensing spectrum and accounting for their joint covariance, is 58σ. 2503.14454v1.pdf	43\sigma

Simple_Different Same The authors of the ACT DR6 paper address the tension between local and global values of H_0 by implementing a procedure that corrects redshifts for expected flows, which helps account for uncertainties due to inhomogeneities. They test for convergence of H_0 on large scales and compare the propagated uncertainty to simulations, concluding that significant differences in H_0 due to inhomogeneities are unlikely. Additionally, they investigate potential systematic errors in the Planck measurement, noting that variations in CMB datasets contribute to the perceived tension with the local value of H_0. Despite these efforts, they acknowledge that some tension persists even when excluding Planck data, suggesting that further direct comparisons and analyses of CMB data may be necessary to fully resolve the discrepancies. [26] 1604.01424v3.pdf	As a baseline assumption, the authors of the ACT DR6 do not combine their data with local measurements of H_0. However, they do discuss models that can accomodate larger values of H_0 and important parameter degeneracies that impact H_0. 

Simple_Different Similar In the ACT DR6 paper, the code libraries used to compute theoretical predictions include HyRec (Ali-Häımoud & Hirata 2011) or CosmoRec (Chluba et al. 2010) for recombination physics, PRIMAT (Pitrou et al. 2018) for Big Bang Nucleosynthesis predictions, HMcode (Mead et al. 2021) for modeling non-linear corrections to the matter power spectrum, and the EDE model implementation in class. 1. 2503.14454v1.pdf  2. 2503.14454v1.pdf  3. 2503.14454v1.pdf  4. 2503.14454v1.pdf	HyRec, CosmoRec and PRIMAT. HMcode is used in a limited capacity.

Simple_Different Same In the ACT DR6 paper, models that alter late-time growth of the universe are handled with caution, as the HMCode is not guaranteed to provide accurate results for such models, particularly those involving interactions between dark matter and dark energy. In these cases, the authors either use custom alternative models or restrict their analysis to linear scales. However, it is noted that most of the new-physics models examined primarily affect the early universe, and their influence on structure formation is typically reflected in a modification of the linear matter power spectrum at the onset of structure formation, which usually remains similar to that of the standard ΛCDM model. 2503.14454v1.pdf	Custom alternatives to HMcode are used or restrictions to linear scales are made.

Simple_Different Different The level of tension in the cosmological parameter determination between the ACT DR6 multi-frequency likelihood and the CMB-only likelihood is indicated by a difference at the 2.8σ level when ignoring correlations between the two datasets. Specifically, the DR6 measurement of Ωbh2 shows an upward shift of 3σ compared to DR4. However, when ACT DR4 is combined with large-scale modes from WMAP, the DR6 results agree with the DR4 + WMAP ΛCDM best-fit model to within 1σ. 2503.14454v1.pdf	No significant tension. Agreement within 0.1\sigma.

Simple_Same Different The 2 statistic for the maximum a posteriori MFLike likelihood for the bbCDM model, using the full P-ACT dataset, is 2180.5. 2503.14454v1.pdf	2180.5

Simple_Different Same ACT DR6 mildly favors a slight positive running of the spectral index, with findings indicating dns/d ln k = 0.0060± 0.0055 (68%, P-ACT) and dns/d ln k = 0.0062± 0.0052 (68%, P-ACT-LB). This suggests a preference for a positive value, while also confirming a vanishing running of the spectral index. 2503.14454v1.pdf	The results disfavour a negative value and midly favours a positive value for the running of the spectral index. There is no statisitically significant evidence in the results to favour or disfavour a zero value.

Simple_Different Different The ACT DR6 paper considers two possible non-decaying isocurvature modes: cold dark matter density (ICDI) and neutrino density (INDI). The baryon density (BDI) mode is not analyzed directly due to its indistinguishable impact on the CMB power compared to CDI, and the neutrino velocity (NVI) mode is not considered because it is less theoretically motivated. 2503.14454v1.pdf	Cold dark matter density (CDI) and neutrino density (NDI) are considered directly. Baryon density (BDI) is considered indirectly.

Simple_Different Same In the n=3 EDE model considered in the ACT DR6 paper, the value of H_0 from the ACT dataset at a 68% confidence level is H_0 = 67.5 +0.9 -1.7. 2503.14454v1.pdf	67.7^{+0.9}_{-1.7}

Simple_Different Different The n=3 EDE model is considered favoured over bb-CDM for the P-ACT-LB dataset at a significance level of less than 2σ. 2503.14454v1.pdf	1.7\sigma

Simple_Different Same According to the ACT DR6 paper, allowing electron mass and spatial curvature to vary at recombination does not explain the discrepancy between local and global values of H_0. While such a model could theoretically accommodate an increased value of H_0 and fit CMB data along with late-time measurements, the joint analysis of P-ACT-LBS showed no significant improvement in the quality of fit compared to P-ACT-LB. Therefore, the evidence does not support a scenario with spatial curvature and a non-standard electron mass at recombination, and the possibility of obtaining a high value of H_0 from this model is significantly reduced. 2503.14454v1.pdf	Once the driving DESI BAO data was replaced with the BOSS BAO data, the H_0 fits shifted to be fully consistent with the \lambda-CDM value. Therefore, no, varying the electron mass and spatial curvature doesn't explain the discrepancy between the local and global values of H_0 

Simple_Different Same The authors of the ACT DR6 paper constrain the effective number of relativistic species (Nidr) from the CMB power spectra by analyzing the primary CMB power spectra and finding that Nidr < 0.339 at 95% confidence. This constraint is significantly tighter than the previous limit from Planck, which was Nidr < 0.379 at 95% confidence. The improvement in the constraint is attributed to the lack of preference for excess high-ℓ damping in the DR6 power spectra. Since additional relativistic species would increase damping, their existence is disfavored by the data, leading to the conclusion that there is no evidence.	N_{eff} alters the damping tail of the CMB power spectra and also induces a characteristic phase shift in the acoustic peaks.

Simple_Different Different The constraints on both N_{eff} and \summ_{\nu} when allowed to vary simultaneously, using the P-ACT-LB dataset at the 95% confidence level (CL), indicate that \Delta N_{eff} is constrained to be less than 0.17. 2503.14454v1.pdf	N_{eff}=2.85\pm0.25, \summ_{\nu}<0.073eV

Simple_Different Same The authors of the ACT DR6 paper model the CMB power spectrum on very small scales of axion-like particle dynamics using several methods. They utilize the axionCAMB Boltzmann solver, which has been previously applied in analyses regarding the impacts of axions on the CMB and large-scale structure (LSS). To accurately model the power on small scales and avoid introducing spurious signals related to axion physics, they implement a modified halo model that incorporates mixed dark matter. Additionally, they employ the axionEmu emulator, which is based on a modified version of CosmoPower. This comprehensive approach allows them to effectively analyze the effects of axions on the CMB power spectrum. 2503.14454v1.pdf	They use a modified halo model, with mixed dark matter.

Simple_Different Same The signs of dark matter annihilation into Standard Model (SM) particles in the Cosmic Microwave Background (CMB) power spectra would include: 1. Damping of high-ℓ power in both temperature and polarization, indicating a reduction in the power of fluctuations at small angular scales.2. Enhancement of the polarization power spectrum at multipole moments ℓ less than or approximately equal to 400, suggesting an increase in the polarization signal at larger scales.3. Shifts of the low-ℓ acoustic peaks in polarization, which would reflect changes in the acoustic oscillations due to the effects of dark matter annihilation. 2503.14454v1.pdf	Damping of high-l power in both temperature and polarization, enhancement of the polarisation power spectrum at l\lesssim400 and shifts of low-l acoustic peaks in polarization.

Simple_Different Similar No information. No relevant sources.	Bayesian constraints on the IDR-IDM model causes \Gamma_{0, nadm} to become degenerate as N_{idr} approaches zero

Simple_Different Same Including fσ8 measurements in the calculation of the growth index increases the tension level with General Relativity (GR) because it effectively breaks degeneracies between the growth index parameter γ and other parameters. This results in constraints that move away from the GR prediction of γ = 0.55 at more than 3σ. Specifically, the central values of γ derived from these constraints deviate from the GR prediction at 3.5σ, indicating a significant discrepancy. The data that contribute to this result primarily come from Redshift Space Distortions (RSD) and peculiar velocity surveys, although the central values remain consistent with analyses that do not include these measurements. 2503.14454v1.pdf	The f\sigma_8 dataset contains two low-z points with low error bars that lie below the CMB expectation for this dataset. Removing these two points removes the tension between the f\sigma_8 dataset and the P-ACT and W-ACT datasets.

Simple_Different Same The extensions to bbCDM considered in the ACT DR6 paper do not help to resolve the tension between the ACT DR6 measurement of H_0 and the 2024 SH0ES measurement. Specifically, degeneracies with extended-model parameters do not align the P-ACT or P-ACT-LB limits with the SH0ES constraints, which indicates that the two measurements remain inconsistent. While the ACT DR6 measurement of H_0 falls within the range of the CCHP measurement, it is still below the latest SH0ES measurement, highlighting the ongoing tension between these results. 【6:1†source】	No. The range of H_0 given by the models studied in the ACT DR6 paper is still lower than the 2024 SH0ES measurement of H_0.

Simple_Different Same The CMB monopole temperature at the 68% confidence level (CL), according to the P-ACT-LB dataset, is TCMB = 2.698 ± 0.016 K. 2503.14454v1.pdf	2.698\pm0.016K

